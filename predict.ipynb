{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"predict.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":["6WCGrHhXHdrQ"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"RR6zGXYuFOUH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import os\n","import sys\n","import h5py\n","import random\n","import pickle\n","try:\n","  import Levenshtein\n","except ImportError:\n","  ! pip install python-levenshtein\n","  import Levenshtein\n","import numpy as np\n","import seaborn as sns\n","\n","import keras\n","import keras.backend as K\n","from keras.layers import Merge\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.preprocessing import sequence\n","from keras.regularizers import l2\n","from keras.layers.wrappers import TimeDistributed\n","from keras.layers.recurrent import LSTM\n","from keras.layers.embeddings import Embedding\n","from keras.layers.core import (\n","    Lambda,\n","    Dense,\n","    Activation,\n","    Dropout,\n","    RepeatVector\n",")\n","from sklearn.cross_validation import train_test_split"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hi2HDwv9Faw9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"984000b0-7f6d-4f2e-a5e2-3307c534d6d4","executionInfo":{"status":"ok","timestamp":1528638211521,"user_tz":-180,"elapsed":479,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["keras.__version__"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.1.6'"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"QBnPBolNFmvq","colab_type":"text"},"cell_type":"markdown","source":["Input data *X* is made from *MAXLEN_DESC* description words followed by  *eos* followed by headline words followed by *eos*. \n","If description is shorter than *MAXLEN_DESC* it will be left padded with empty.\n","if entire data is longer than *MAXLEN* it will be clipped and if it is shorter it will be padded.\n","\n","Labels *Y* are the headline words followed by *eos* and clipped or padded to *MAXLEN_HEAD*."]},{"metadata":{"id":"r6bDOSA-F5zK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# model global params\n","MAXLEN_DESC=25\n","MAXLEN_HEAD=25\n","MAXLEN = MAXLEN_DESC + MAXLEN_HEAD\n","RNN_SIZE = 128\n","RNN_LAYERS = 3\n","BATCH_NORMALIZATION=False\n","ACTIVATION_RNN_SIZE = 40 if MAXLEN_DESC else 0\n","\n","# data global params\n","DATA_FOLDER = 'drive/text_summarization/data'\n","WEIGHTS_FILENAME = 'train_weights.hdf5'\n","EMBEDDINGS_FILENAME = 'vocabulary-embedding'\n","\n","WEIGHTS_PATH = os.path.join(DATA_FOLDER, WEIGHTS_FILENAME)\n","VOCABULARY_EMBEDDINGS_PATH = os.path.join(DATA_FOLDER, EMBEDDINGS_FILENAME)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jHppdkMHG66s","colab_type":"text"},"cell_type":"markdown","source":["The output of the first *ACTIVATION_RNN_SIZE* nodes from the top layer will be used for activation and the rest will be used to select predicted word"]},{"metadata":{"id":"MRrLSv-pG9sx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# model training parameters\n","SEED=42\n","LSTM_DROPOUT, LSTM_RECURRENT_DROPOUT, DROPOUT_RATE , WEIGHT_DECLAY = 0, 0, 0, 0\n","REGULARIZER = l2(WEIGHT_DECLAY) if WEIGHT_DECLAY else None\n","OPTIMIZER = 'adam'\n","BATCH_SIZE=64\n","UNKNOWN_WORDS_COUNT = 100\n","\n","random.seed(SEED)\n","np.random.seed(SEED)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_0982Fj5HBCU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# load embeddings\n","with open(\"{}.pkl\".format(VOCABULARY_EMBEDDINGS_PATH), \"rb\") as fp:\n","    EMBEDDING, INDEX_TO_WORD, WORD_TO_INDEX, GLOVE_INDEX_TO_INDEX = pickle.load(fp)\n","\n","# load all data\n","with open(\"{}.data.pkl\".format(VOCABULARY_EMBEDDINGS_PATH), \"rb\") as fp:\n","    X, Y = pickle.load(fp)\n","\n","VOCAB_SIZE, EMBEDDING_SIZE = EMBEDDING.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7oDi5fZCHCzZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":119},"outputId":"8771fb19-fce9-4d85-d128-2f25dc419deb","executionInfo":{"status":"ok","timestamp":1528638230683,"user_tz":-180,"elapsed":1746,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["print ('data size: X = {}, Y = {}'.format(len(X), len(Y)))\n","print ('embeddings size: {}'.format(EMBEDDING_SIZE))\n","print ('vocabulary size: ', VOCAB_SIZE, 'the last {} words can be used as place holders for unknown words'.format(UNKNOWN_WORDS_COUNT))\n","print ('different words count: INDEX_TO_WORD = {}, WORD_TO_INDEX = {}'.format(len(INDEX_TO_WORD), len(WORD_TO_INDEX)))\n","print ('words outside vocabulary which we can substituted using glove:', len(GLOVE_INDEX_TO_INDEX))\n","print ('number of unknown words: ', len(INDEX_TO_WORD) - VOCAB_SIZE - len(GLOVE_INDEX_TO_INDEX))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["data size: X = 1000000, Y = 1000000\n","embeddings size: 100\n","vocabulary size:  40000 the last 100 words can be used as place holders for unknown words\n","different words count: INDEX_TO_WORD = 1557454, WORD_TO_INDEX = 1557454\n","words outside vocabulary which we can substituted using glove: 185463\n","number of unknown words:  1331991\n"],"name":"stdout"}]},{"metadata":{"id":"JgdzJb3IHHB4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# unknown words\n","for i in range(UNKNOWN_WORDS_COUNT):\n","    INDEX_TO_WORD[VOCAB_SIZE - i - 1] = \"<{}>\".format(i)\n","\n","#  out of vocabulary words\n","for i in range(VOCAB_SIZE - UNKNOWN_WORDS_COUNT, len(INDEX_TO_WORD)):\n","    INDEX_TO_WORD[i] = INDEX_TO_WORD[i] + '^'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WOTMD-jwHJhS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"8dc6b1bb-717c-4ee3-aaab-c525bc419af8","executionInfo":{"status":"ok","timestamp":1528638233941,"user_tz":-180,"elapsed":1357,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["# reduce sample size.\n","# For training we reduced sample size.\n","# This is done only because of our restriction on GPU capacity.\n","reduce_sample_size = 10\n","\n","new_example_size = len(X) // reduce_sample_size\n","val_samples_count = int(new_example_size * 0.1)\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X[:new_example_size], Y[:new_example_size], test_size=val_samples_count, random_state=SEED)\n","print(\"Train size: {}, Test size: {}\".format(len(X_train), len(X_test)))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Train size: 90000, Test size: 10000\n"],"name":"stdout"}]},{"metadata":{"id":"keKuDnnoHLTP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# handle empty and end of sequence\n","empty = 0\n","eos = 1\n","INDEX_TO_WORD[empty] = '_'\n","INDEX_TO_WORD[eos] = '~'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F0FuzouCHLub","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":71},"outputId":"701bebef-985f-4bee-f008-0f88183203f7","executionInfo":{"status":"ok","timestamp":1528647785916,"user_tz":-180,"elapsed":874,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["# show how data looks like    \n","def print_sample(label, sample):\n","    print(label + ':', end=' '),\n","    for index in sample:\n","        print(INDEX_TO_WORD[index], end=' '),\n","    print()\n","    \n","    \n","print_sample('Head', Y_train[9111])\n","print_sample('Desc', X_train[9111])"],"execution_count":317,"outputs":[{"output_type":"stream","text":["Head: Microsoft Acquires Popular Android App Echo Notification Lockscreen^ \n","Desc: Microsoft has acquired Double Labs , an Android app startup which develops the popular Echo Notification Lockscreen^ for Android devices . This app had received between 1 million and 5 million downloads so far in Play Store . \n"],"name":"stdout"}]},{"metadata":{"id":"6OrO9oEnHQ6g","colab_type":"text"},"cell_type":"markdown","source":["# Model"]},{"metadata":{"id":"QQ9dE3LaHSFP","colab_type":"text"},"cell_type":"markdown","source":["## base rnn model"]},{"metadata":{"id":"o2oAsW-lHUiN","colab_type":"text"},"cell_type":"markdown","source":["Standard stacked LSTM model identical to one used during training"]},{"metadata":{"id":"242z0BUUHXNx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["rnn_model = Sequential()\n","rnn_model.add(Embedding(\n","    VOCAB_SIZE, EMBEDDING_SIZE, input_length=MAXLEN,\n","    embeddings_regularizer=REGULARIZER, weights=[EMBEDDING],\n","    mask_zero=True, name='embedding_1'))\n","\n","for i in range(RNN_LAYERS):\n","    lstm = LSTM(RNN_SIZE, return_sequences=True,\n","                kernel_regularizer=REGULARIZER, bias_regularizer=REGULARIZER,\n","                recurrent_regularizer=REGULARIZER, dropout=LSTM_DROPOUT,\n","                recurrent_dropout=LSTM_RECURRENT_DROPOUT,\n","                name='lstm_{}'.format(i+1)\n","                  )\n","    rnn_model.add(lstm)\n","    rnn_model.add(Dropout(DROPOUT_RATE, name='dropout_{}'.format(i+1)))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2STuwPNcHY_R","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":374},"outputId":"690ac511-34d7-4491-f705-1e9e9a5a7072","executionInfo":{"status":"ok","timestamp":1528638240305,"user_tz":-180,"elapsed":928,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["rnn_model.summary()"],"execution_count":34,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 50, 100)           4000000   \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 50, 128)           117248    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 50, 128)           0         \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 50, 128)           131584    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 50, 128)           0         \n","_________________________________________________________________\n","lstm_3 (LSTM)                (None, 50, 128)           131584    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 50, 128)           0         \n","=================================================================\n","Total params: 4,380,416\n","Trainable params: 4,380,416\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"6WCGrHhXHdrQ","colab_type":"text"},"cell_type":"markdown","source":["## load weights"]},{"metadata":{"id":"DcEeGvBFHaaU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def load_weights(model, filepath):\n","    \"\"\"\n","    Load as much weights as possible from given file\n","    \"\"\"\n","    print(\"Loading {} to {}\".format(filepath, model.name))\n","    with h5py.File(filepath, mode='r') as file:\n","        layer_names = [n.decode('utf8') for n in file.attrs['layer_names']]\n","        weights_tuples = []\n","        for name in layer_names:\n","            print(\"Loading layer: {}\".format(name))\n","            # for each layer\n","            weight_names = [n.decode('utf8') for n in file[name].attrs['weight_names']]\n","            \n","            if len(weight_names):\n","                weights = [file[name][weight_name] for weight_name in weight_names]\n","                try:\n","                    layer = model.get_layer(name=name)\n","                except:\n","                    layer = None\n","                if not layer:\n","                    print(\"Failed to find layer {}\".format(name))\n","                    weights = [np.array(w) for w in weights]\n","                    break\n","\n","                all_weights = layer.trainable_weights + layer.non_trainable_weights\n","                weights_tuples += zip(all_weights, weights)\n","                \n","        K.batch_set_value(weights_tuples)\n","    return weights"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R_eT9Xd4Hk41","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":204},"outputId":"1bd78aad-89b2-4ca4-977c-8965b21491ae","executionInfo":{"status":"ok","timestamp":1528638243948,"user_tz":-180,"elapsed":1968,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["weights = load_weights(rnn_model, WEIGHTS_PATH)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Loading drive/text_summarization/data/train_weights.hdf5 to sequential_3\n","Loading layer: embedding_1\n","Loading layer: lstm_1\n","Loading layer: dropout_1\n","Loading layer: lstm_2\n","Loading layer: dropout_2\n","Loading layer: lstm_3\n","Loading layer: dropout_3\n","Loading layer: simplecontext_1\n","Loading layer: time_distributed_2\n","Failed to find layer time_distributed_2\n"],"name":"stdout"}]},{"metadata":{"id":"JYG0IhuMNWPZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"dda3f83f-e5c4-4eae-fa68-c9015dd20b64","executionInfo":{"status":"ok","timestamp":1528638245140,"user_tz":-180,"elapsed":1128,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["# shape of loaded weights\n","[w.shape for w in weights]"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(176, 40000), (40000,)]"]},"metadata":{"tags":[]},"execution_count":37}]},{"metadata":{"id":"RzU43iOJKe6c","colab_type":"text"},"cell_type":"markdown","source":["## final headline model"]},{"metadata":{"id":"qSpn_SRTMmyZ","colab_type":"text"},"cell_type":"markdown","source":["For each word in this part it concatenate the output of the previous layer (RNN) with a weighted average of the outputs of the description part. In this only the last RNN_SIZE - ACTIVATION_RNN_SIZE are used from each output. The first ACTIVATION_RNN_SIZE output is used to compute the weights for the averaging."]},{"metadata":{"id":"pJGGRHTdMju6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["context_weight = K.variable(1.)\n","head_weight = K.variable(1.)\n","\n","def simple_context(X, mask, size=ACTIVATION_RNN_SIZE, maxlen_desc=MAXLEN_DESC, maxlen_head=MAXLEN_HEAD):\n","    desc, head = X[:,:maxlen_desc], X[:,maxlen_desc:]\n","    head_activations, head_words = head[:,:,:size], head[:,:,size:]\n","    desc_activations, desc_words = desc[:,:,:size], desc[:,:,size:]\n","    \n","    # activation for every head word and every desc word\n","    activation_energies = K.batch_dot(head_activations, desc_activations, axes=(2,2))\n","    \n","    # make sure we don't use description words that are masked out\n","    if mask is not None:\n","      activation_energies = activation_energies + \\\n","      -1e20 * K.expand_dims(1.- K.cast(mask[:, :maxlen_desc], 'float32'), 1)\n","    \n","    # for every head word compute weights for every desc word\n","    activation_energies = K.reshape(activation_energies,(-1, maxlen_desc))\n","    activation_weights = K.softmax(activation_energies)\n","    activation_weights = K.reshape(activation_weights,(-1, maxlen_head, maxlen_desc))\n","\n","    # for every head word compute weighted average of desc words\n","    desc_avg_word = K.batch_dot(activation_weights, desc_words, axes=(2,1))\n","    return K.concatenate((context_weight * desc_avg_word, head_weight * head_words))\n","\n","\n","class SimpleContext(Lambda):\n","    def __init__(self, **kwargs):\n","        super(SimpleContext, self).__init__(simple_context, **kwargs)\n","        self.supports_masking = True\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return input_mask[:, MAXLEN_DESC:]    \n","    \n","    def get_output_shape_for(self, input_shape):\n","        nb_samples = input_shape[0]\n","        return (nb_samples, MAXLEN_HEAD, 2 * (RNN_SIZE - ACTIVATION_RNN_SIZE))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r5l0G96QJ7gq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# define final model\n","model = Sequential()\n","model.add(rnn_model)\n","\n","if ACTIVATION_RNN_SIZE:\n","    model.add(SimpleContext(name='simplecontext_1'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"isX0FCV0PLs6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":204},"outputId":"33e925f8-676f-4dad-bfa6-1c62c03cc590","executionInfo":{"status":"ok","timestamp":1528638248620,"user_tz":-180,"elapsed":477,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["model.summary()"],"execution_count":40,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sequential_3 (Sequential)    (None, 50, 128)           4380416   \n","_________________________________________________________________\n","simplecontext_1 (SimpleConte (None, 25, 176)           0         \n","=================================================================\n","Total params: 4,380,416\n","Trainable params: 4,380,416\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"zytvDpsaPSDO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kWtqeYbJQDXH","colab_type":"text"},"cell_type":"markdown","source":["## test shapes"]},{"metadata":{"id":"Fn4wd96fP85U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def left_padd(x, maxlen_desc=MAXLEN_DESC, eos=eos):\n","    \"\"\"\n","    left pad a description to maxlen_desc and then add eos.\n","    \"\"\"\n","    if maxlen_desc == 0:\n","        return [eos]\n","    size = len(x)\n","    if size > maxlen_desc:\n","        x = x[-maxlen_desc:]\n","        size = maxlen_desc\n","    return [empty] * (maxlen_desc - size) + x + [eos]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J7eANiR5XxLo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_samples = [[empty] * MAXLEN_DESC + [eos]]\n","data = sequence.pad_sequences(test_samples, maxlen=MAXLEN, value=empty, padding='post', truncating='post')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WoafvM9xXw7d","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":68},"outputId":"737f1103-c4ab-4ed1-e39d-ebda4ca420e1","executionInfo":{"status":"ok","timestamp":1528638251476,"user_tz":-180,"elapsed":719,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["data"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":44}]},{"metadata":{"id":"eiVC-ngvXwcM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"fc5b00cc-21f2-4ef2-8594-61aa6a12abf9","executionInfo":{"status":"ok","timestamp":1528638252511,"user_tz":-180,"elapsed":530,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["# check eos\n","np.all(data[:,MAXLEN_DESC] == eos)"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":45}]},{"metadata":{"id":"3x2YHlG2XwMb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"5f510011-cba0-4190-e5d6-a4da0cebf344","executionInfo":{"status":"ok","timestamp":1528638254213,"user_tz":-180,"elapsed":1223,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["data.shape"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 50)"]},"metadata":{"tags":[]},"execution_count":46}]},{"metadata":{"id":"Tr3bY0iGXwAX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"19b1e1e7-8b7d-4052-a8e3-1d38a6d7025d","executionInfo":{"status":"ok","timestamp":1528638256178,"user_tz":-180,"elapsed":1446,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["probs = model.predict(data, verbose=0, batch_size=1)\n","probs.shape"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 25, 176)"]},"metadata":{"tags":[]},"execution_count":47}]},{"metadata":{"id":"a1qs7gWrRoed","colab_type":"text"},"cell_type":"markdown","source":["# Test sample generation"]},{"metadata":{"id":"17mbf4m7aL19","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def get_sample(energy, n, temperature):\n","    \"\"\"\n","    Used in Beam search. Sample at most n different elements\n","    according to their energy \n","    \"\"\"\n","    res = []\n","    size = min(n, len(energy))\n","    probs = np.exp(-np.array(energy) / temperature )\n","    for i in range(size):\n","        max_i = np.argmax(np.random.multinomial(1, probs / np.sum(probs), 1))\n","        res.append(max_i)\n","        probs[max_i] = 0.0 # select each element only once\n","    return res"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qO27TPz7RpPJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def beamsearch(predict, k, start=[empty] * MAXLEN_DESC + [eos],\n","               maxsample=MAXLEN, oov=VOCAB_SIZE-1, \n","               empty=empty, eos=eos, temperature=1.0):\n","    \"\"\"\n","    Standard Beam search. Return k samples and their NLL scores.\n","    All samples starts with an `empty` label and end with `eos` \n","    or truncated to length of `maxsample`.\n","    `predict` model that returns label probability of each sample.\n","    \"\"\"\n","    dead_samples = []\n","    dead_scores = []\n","    live_scores = [0]\n","    live_samples = [start]\n","\n","    while live_samples:\n","        # for every live sample get prob for every label \n","        probs = predict(live_samples, empty=empty)\n","        \n","        # total score for every sample is sum of -log of word probs\n","        sample_score = np.array(live_scores)[:, None] - np.log(probs)\n","        sample_score[:, empty] = 1e20\n","\n","        live_scores = list(sample_score.flatten())\n","\n","        # find the best (lowest) scores we have from all possible dead samples\n","        # and all live samples and all possible new words added\n","        scores = dead_scores + live_scores\n","        ranks = get_sample(scores, k, temperature)\n","        n = len(dead_scores)\n","        dead_scores = [dead_scores[r] for r in ranks if r < n]\n","        dead_samples = [dead_samples[r] for r in ranks if r < n]\n","        \n","        live_scores = [live_scores[r - n] for r in ranks if r >= n]\n","        live_samples = [live_samples[(r - n) // VOCAB_SIZE] + \\\n","                        [(r - n) % VOCAB_SIZE] for r in ranks if r >= n]\n","\n","        # even if len(live_samples) == maxsample we dont want it dead\n","        # last prediction out of it to reach a headline of MAXLEN_HEAD\n","        def is_zombie(s): return s[-1] == eos or len(s) > maxsample\n","        \n","        # add zombies to the dead\n","        dead_scores += [c for s, c in zip(live_samples, live_scores) \n","                        if is_zombie(s)]\n","        dead_samples += [s for s in live_samples if is_zombie(s)]\n","        \n","        # remove zombies from the living \n","        live_scores = [c for s, c in zip(live_samples, live_scores) \n","                       if not is_zombie(s)]\n","        live_samples = [s for s in live_samples if not is_zombie(s)]\n","\n","    return dead_samples, dead_scores"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SIGR1mnRs75X","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# top dense of the trained model\n","def convert_to_probs(output):\n","    output = np.dot(output, weights[0]) + weights[1]\n","    output -= output.max()\n","    output = np.exp(output)\n","    output /= output.sum()\n","    return output"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OJtWyswuTnUx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def custom_predict(samples, empty=empty, model=model, maxlen=MAXLEN):\n","    \"\"\"\n","    For every sample, calculate probability for every possible label.\n","    \"\"\"\n","    sample_lengths = list(map(len, samples))\n","    data = sequence.pad_sequences(samples, maxlen=MAXLEN, value=empty, padding='post', truncating='post')\n","    model_predict = model.predict(data, verbose=0, batch_size=BATCH_SIZE)\n","    return np.array([\n","        convert_to_probs(prob[sample_length - MAXLEN_DESC - 1]) \n","        for prob, sample_length in zip(model_predict, sample_lengths)\n","    ])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RywXDmfMT6kI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def fold_vocabulary(words):\n","    \"\"\"\n","    Convert list of word indexes that may contain words outside VOCAB_SIZE to words inside.\n","    If a word is outside, try first to use GLOVE_INDEX_TO_INDEX to find a similar word inside.\n","    If none exist then replace all occurances of the same unknown word with <0>, <1>, etc\n","    \"\"\"\n","    words = [x if x < VOCAB_SIZE - UNKNOWN_WORDS_COUNT else GLOVE_INDEX_TO_INDEX.get(x,x) for x in words]\n","    # the more popular word is <0> and so on\n","    outside = sorted([x for x in words if x >= VOCAB_SIZE - UNKNOWN_WORDS_COUNT])\n","    # if there are more than UNKNOWN_WORDS_COUNT oov words then put them all in UNKNOWN_WORDS_COUNT-1\n","    outside = dict((x, VOCAB_SIZE - 1 - min(i, UNKNOWN_WORDS_COUNT-1)) for i, x in enumerate(outside))\n","    words = [outside.get(x,x) for x in words]\n","    return words"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rTkCTUngUFdO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def unfold_vocabulary(desc, words):\n","    \"\"\" Reverse operation to fold_vocabulary \"\"\"\n","    unfold = {}\n","    for i, unfold_idx in enumerate(desc):\n","        fold_idx = words[i]\n","        if fold_idx >= VOCAB_SIZE - UNKNOWN_WORDS_COUNT:\n","            unfold[fold_idx] = unfold_idx\n","    return [unfold.get(x,x) for x in words]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dLykrLMsUZqn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def gensamples(X=None, X_test=None, Y_test=None, skips=2, k=10, batch_size=BATCH_SIZE, short=True, temperature=1.):\n","    \"\"\"\n","    Generates samples with best score using custom_predict and Beam search\n","    \"\"\"  \n","    x = [WORD_TO_INDEX[w.rstrip('^')] for w in X.split()]\n","\n","    print('HEADS: ')\n","    samples = []\n","    if MAXLEN_DESC == 0:\n","        skips = [0]\n","    else:\n","        skips = range(min(MAXLEN_DESC, len(x)), max(MAXLEN_DESC, len(x)), abs(MAXLEN_DESC - len(x)) // skips + 1)\n","    for s in skips:\n","        start = left_padd(x[:s])\n","        fold_start = fold_vocabulary(start)\n","        sample, score = beamsearch(predict=custom_predict, start=fold_start,\n","                                   k=k, temperature=temperature)\n","        samples += [(s, start, score) for s, score in zip(sample, score)]\n","    \n","    # sort samples\n","    samples.sort(key=lambda x: x[-1])\n","    codes = []\n","    for sample, start, score in samples:\n","        code = ''\n","        words = []\n","        sample = unfold_vocabulary(start, sample)[len(start):]\n","        for w in sample:\n","            if w == eos:\n","                break\n","            words.append(INDEX_TO_WORD[w])\n","            code += chr(w // (256 * 256)) + chr((w // 256) % 256) + chr(w % 256)\n","        if short:\n","            distance = min([100] + [-Levenshtein.jaro(code,c) for c in codes])\n","            if distance > -0.6:\n","                print(\"{} {}\".format(score, ' '.join(words)))\n","        else:\n","            print(\"{} {}\".format(score, ' '.join(words)))\n","        codes.append(code)\n","    return samples"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q0sQj6Y_Wiyi","colab_type":"text"},"cell_type":"markdown","source":["Examples:"]},{"metadata":{"id":"7FUM5pXUkWRD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["X = \"Christopher Nolan 's next movie will be released on July 21st , 2017 . The 45-year-old filmmaker - who 's directed some of the biggest hits in recent years , including Inception and Interstellar - is to make the as-yet-untitled movie for his long-time partner Warner Bros and has instructed everyone connected to the project to keep its details a secret , according to The Hollywood Reporter .\"\n","Y = \"Christopher Nolan 's new film gets release date\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"tN69vkoZWlZZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"afeaaa06-d795-4b5f-c7db-225cd7b1bc71","executionInfo":{"status":"ok","timestamp":1528642503916,"user_tz":-180,"elapsed":13212,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["samples = gensamples(X=X, k=10, skips=2, batch_size=BATCH_SIZE, temperature=1.)"],"execution_count":152,"outputs":[{"output_type":"stream","text":["HEADS: \n","18.383082628250122 : to first\n"],"name":"stdout"}]},{"metadata":{"id":"2I_NHU415BCA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["X = \"Shares of Toronto-Dominion^ Bank ( NYSE : TD ) have been given an average recommendation of “Buy” by the eleven research firms that are currently covering the firm , Market Beat Ratings reports . One equities research analyst has rated the stock with a sell rating , three have assigned a hold rating and six have given a buy rating to the company .\"\n","Y = \"Toronto-Dominion^ Bank Receives $ 56.75^ Average Target Price from Analysts ( NYSE : TD )\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"6eOlcpfA5C-t","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"1554a47b-c916-451e-bbeb-000529d6cba6","executionInfo":{"status":"ok","timestamp":1528638458735,"user_tz":-180,"elapsed":18043,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["samples = gensamples(X=X, k=10, skips=2, batch_size=BATCH_SIZE, temperature=1.)"],"execution_count":68,"outputs":[{"output_type":"stream","text":["HEADS: \n","34.63547205924988 of Products Market Toronto-Dominion^ , ( Report\n"],"name":"stdout"}]},{"metadata":{"id":"pr8JiAxh6xq1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["X = \"Sydney-based^ strategic integrated communications agency , Zadro^ , has moved to the next level ; due to the business expansion , they are commencing a new chapter in their growth by relocating to a bigger , better and brighter office space in Surry Hills . Felicity^ Zadro^ , Managing Director , Zadro^ , says the move is indicative of the way the agency has flourished^ since its inception eight years ago .\"\n","Y = \"Integrated communications agency , Zadro^ , moves to the next level \""],"execution_count":0,"outputs":[]},{"metadata":{"id":"81MorRNz65k4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":374},"outputId":"ac46fa69-454e-406e-ece7-c664067b114f","executionInfo":{"status":"ok","timestamp":1528646542777,"user_tz":-180,"elapsed":9463,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["samples = gensamples(X=X, k=10, skips=2, batch_size=BATCH_SIZE, temperature=1., short=False)\n"],"execution_count":268,"outputs":[{"output_type":"stream","text":["HEADS: \n","15.158374309539795 Zadro^ into\n","22.767340421676636 : man , for\n","25.752980589866638 Khang Sydney-based^ Your in\n","31.19711208343506 : man , for in of\n","33.33200526237488 Khang Sydney-based^ Your in ( )\n","33.389075756073 Khang Sydney-based^ Your in ( Sydney-based^\n","37.114909648895264 Khang Sydney-based^ Your in ( Sydney-based^ )\n","40.732621908187866 Khang Sydney-based^ Your in ( Sydney-based^ ) ,\n","44.883264899253845 : man , for in of | Week\n","46.78041231632233 Khang Sydney-based^ Your in ( Sydney-based^ ) , In\n","48.34776163101196 : man , for in the Wire in Zadro^\n","48.40708410739899 : man , for in the Wire in in\n","48.86311888694763 Khang Sydney-based^ Your in ( Sydney-based^ ) , Zadro^ ,\n","52.33882141113281 : man , for in the Wire in Zadro^ in\n","56.21885633468628 Khang Sydney-based^ Your in ( Sydney-based^ ) , Zadro^ , Share\n","56.60913872718811 : man , for in the Wire in Zadro^ in ,\n","61.65643393993378 Khang Sydney-based^ Your in ( Sydney-based^ ) , Zadro^ , Share '\n","63.978535175323486 : man , for in the Wire in Zadro^ in , House\n","79.78243720531464 Khang Sydney-based^ Your in ( Sydney-based^ ) , Zadro^ , Share ' Inc. Keep\n","88.09660124778748 : man , for in the Wire in Zadro^ in , House calculator vacate\n"],"name":"stdout"}]},{"metadata":{"id":"Ni2WzYjgIjlB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["X = \"Microsoft has acquired Double Labs , an Android app startup which develops the popular Echo Notification Lockscreen for Android devices . This app had received between 1 million and 5 million downloads so far in Play Store . \"\n","Y = \"Microsoft Acquires Popular Android App Echo Notification Lockscreen^ \""],"execution_count":0,"outputs":[]},{"metadata":{"id":"tPAkpF4wIqiY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":374},"outputId":"a38105f3-fee3-4298-c30e-7b5592e56915","executionInfo":{"status":"ok","timestamp":1528649042573,"user_tz":-180,"elapsed":11233,"user":{"displayName":"Yurii Mykhalchuk","photoUrl":"//lh5.googleusercontent.com/-m6b7ZpCuLJk/AAAAAAAAAAI/AAAAAAAAAD4/USPBhLQTf7E/s50-c-k-no/photo.jpg","userId":"110381956251426546831"}}},"cell_type":"code","source":["samples = gensamples(X=X, k=10, skips=2, batch_size=BATCH_SIZE, temperature=1., short=False)"],"execution_count":358,"outputs":[{"output_type":"stream","text":["HEADS: \n","11.164496660232544 : Lockscreen^\n","17.4766845703125 : Lockscreen^ of Lockscreen^\n","24.58097004890442 : Lockscreen^ of Lockscreen^ ( )\n","28.738329887390137 : Lockscreen^ of Lockscreen^ ( ) and\n","31.96679711341858 : Lockscreen^ of Lockscreen^ ( ) Lockscreen^ to\n","36.09665632247925 Lockscreen^ : be In next in\n","39.28780651092529 Lockscreen^ : be In next in Lockscreen^\n","39.65440595149994 : Lockscreen^ of Lockscreen^ ( ) Lockscreen^ to Citigroup\n","46.90165972709656 Lockscreen^ : be In next in Lockscreen^ in Lockscreen^\n","47.96070921421051 : Lockscreen^ of Lockscreen^ ( ) Lockscreen^ to Citigroup Senior\n","48.542194962501526 : Lockscreen^ of Lockscreen^ ( ) Lockscreen^ in Iran Analysis\n","51.04038429260254 Lockscreen^ : be In next in Lockscreen^ in Lockscreen^ )\n","52.64095377922058 Lockscreen^ : be In next in Lockscreen^ for ) ?\n","59.06521785259247 Lockscreen^ : be In next in Lockscreen^ for ) of 3\n","59.90263086557388 Lockscreen^ : be In next in Lockscreen^ for ) of Australian\n","62.37356781959534 : Lockscreen^ of Lockscreen^ ( ) Lockscreen^ Data @ of Showcase Lockscreen^ )\n","64.49380505084991 Lockscreen^ : be In next in Lockscreen^ for ) of 3 a\n","71.37919330596924 : Lockscreen^ of Lockscreen^ ( ) Lockscreen^ Data @ of Showcase Lockscreen^ ) Five\n","74.47290134429932 Lockscreen^ : be In next in Lockscreen^ for ) of 3 a recover\n","83.59657984972 Lockscreen^ : be In next in Lockscreen^ for ) of 3 a postponed being\n"],"name":"stdout"}]}]}